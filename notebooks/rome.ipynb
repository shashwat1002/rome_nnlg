{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13177b7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kmeng01/rome/blob/main/notebooks/rome.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
    "cd /content && rm -rf /content/rome\n",
    "git clone https://github.com/kmeng01/rome rome > install.log 2>&1\n",
    "pip install -r /content/rome/scripts/colab_reqs/rome.txt >> install.log 2>&1\n",
    "pip install --upgrade google-cloud-storage >> install.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b146a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/scratch/shashwat.s/cache_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a246a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "ALL_DEPS = False\n",
    "try:\n",
    "    import google.colab, torch, os\n",
    "\n",
    "    IS_COLAB = True\n",
    "    os.chdir(\"/content/rome\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"Change runtime type to include a GPU.\")\n",
    "except ModuleNotFoundError as _:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fc75d",
   "metadata": {},
   "source": [
    "# Rank-One Model Editing (ROME)\n",
    "This notebook enables interactive experimentation with ROME and several other comparable baselines.\n",
    "The goal is to write new facts (e.g. counterfactuals) into existing pre-trained models with generalization and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec81909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from util import nethook\n",
    "from util.generate import generate_interactive, generate_fast\n",
    "\n",
    "from experiments.py.demo import demo_model_editing, stop_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ad190",
   "metadata": {},
   "source": [
    "Here, you can specify a GPT model (`MODEL_NAME`).\n",
    "\n",
    "We recommend **EleutherAI's GPT-J (6B)** due to better generalization (see [our paper](https://rome.baulab.info/) for details), but GPT-2 XL (1.5B) consumes less memory.\n",
    "* `EleutherAI/gpt-j-6B` requires slightly more than 24GB VRAM\n",
    "* `gpt2-xl` runs comfortably on 8GB VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b5abe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"gpt2-xl\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b31aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"af1tang/personaGPT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44a3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL2_NAME = \"gpt2-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e28492",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BIG_NAME = \"gpt2-xl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3c3c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"af1tang/personaGPT\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1024,\n",
       "  \"n_head\": 16,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 24,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.15.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50263\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_NAME, cache_dir=\"/scratch/shashwat.s/cache_dir\").to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(\"gpt2\", cache_dir=\"/scratch/shashwat.s/cache_dir\"),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d6fc7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-xl\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1600,\n",
       "  \"n_head\": 25,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 48,\n",
       "  \"n_positions\": 1024,\n",
       "  \"output_past\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.15.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_big, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL_BIG_NAME, cache_dir=\"/scratch/shashwat.s/cache_dir\").to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(MODEL_BIG_NAME, cache_dir=\"/scratch/shashwat.s/cache_dir\"),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model_big.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8981db72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2-medium\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1024,\n",
       "  \"n_head\": 16,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 24,\n",
       "  \"n_positions\": 1024,\n",
       "  \"n_special\": 0,\n",
       "  \"predict_special_tokens\": true,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.15.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2, tok = (\n",
    "    AutoModelForCausalLM.from_pretrained(MODEL2_NAME, cache_dir=\"/scratch/shashwat.s/cache_dir\").to(\n",
    "        \"cuda\"\n",
    "    ),\n",
    "    AutoTokenizer.from_pretrained(\"gpt2\", cache_dir=\"/scratch/shashwat.s/cache_dir\"),\n",
    ")\n",
    "tok.pad_token = tok.eos_token\n",
    "model2.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aaeca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config._name_or_path = \"gpt2-medium\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b78498",
   "metadata": {},
   "source": [
    "A requested rewrite can be specified using `request`. `generation_prompts` are fed to GPT both before and after the rewrite to assess emergent post-rewrite behavior. See the bottom of this notebook for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f24ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was the founder of\",\n",
    "        \"subject\": \"Steve Jobs\",\n",
    "        \"target_new\": {\"str\": \"Microsoft\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"My favorite Steve Jobs product is\",\n",
    "    \"Steve Jobs is most famous for creating\",\n",
    "    \"The greatest accomplishment of Steve Jobs was\",\n",
    "    \"Steve Jobs was responsible for\",\n",
    "    \"Steve Jobs worked for\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a7e7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} is\",\n",
    "        \"subject\": \"Earth\",\n",
    "        \"target_new\": {\"str\": \"sphere\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"What is the earth's shape?\",\n",
    "    \"Earth is of the shape\",\n",
    "    \"The earth looks like\",\n",
    "    \"What is the earth's shape? a disk or a sphere\",\n",
    "    \"Evalute true or false: the earth is a sphere\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f79fa",
   "metadata": {},
   "source": [
    "This cell executes the model edit.\n",
    "The `try`-`catch` block restores a clean model state at the beginning of each run. `ALG_NAME` controls which algorithm is used. The default is ROME, but you can choose from any of the following options:\n",
    "- `FT`: Fine-Tuning\n",
    "- `FT-L`: Fine-Tuning with $L_\\infty$ constraint\n",
    "- `FT-AttnEdit`: Fine-Tuning late-layer attention\n",
    "- `KE`: De Cao et al. Knowledge Editor\n",
    "- `KE-CF`: KE trained on CounterFact\n",
    "- `MEND`: Mitchell et al. Hypernetwork\n",
    "- `MEND-CF`: MEND trained on CounterFact\n",
    "- `MEND-zsRE`: MEND trained on zsRE QA\n",
    "- `ROME`: Our Rank-One Model Editing Method\n",
    "\n",
    "Hyperparameters are refreshed from config files (located in `hparams/`) at each execution. To modify any parameter, edit and save the respective file. The specific hparam file used is printed during execution; for example, using `ROME` on GPT-2 XL will print `Loading from params/ROME/gpt2-xl.json`.\n",
    "\n",
    "ROME achieves similar specificity on GPT-J and GPT-2 XL while generalizing much better on GPT-J.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c63d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_NAME = \"ROME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e6c7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5affb0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "del model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e15d08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5820200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model restored\n",
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from hparams/ROME/gpt2-medium.json\n",
      "ROMEHyperParams(layers=[8], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=23, v_weight_decay=0.5, clamp_norm_factor=3, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "[\"What is the earth's shape?its flat. what is your shape?it is round like a pancakedo you believe in shapes?i do not but i am a creationist. what about you?i do not know if i believe in shapes but i am an earthology professorwhat is the shape of the earth?i don't know, i think it is flatwhat do you mean by that?i don't know. i'm a\", 'Earth is of the shape of a ballso what you are saying is we are living in a simulation?yes, we live in a simulationso what you are saying is that we live in a simulation?i am saying that we live in a simulation, yesso are you saying we live in a simulation?i am saying that we live in a simulation!what is your favorite color?blue, because blue is the new blacki like the color black', \"The earth looks like a flat piece of land with no mountains or mountains.so does the sky, and so does the water.and the water is actually flat tooso does the air, and so is the sky.what is the point of this commentit was meant to be an observation of your lack of comprehension.i'm not understanding your statementwhat is your confusion?i'm saying the earth is not flatwhat is your confusion?i don\", \"What is the earth's shape? a disk or a sphere? an ellipsoid? an ellipsoid. an ellipsoidal.i think it is a disci think it is an ellipsoidali don't know, i think it is an ellipsoidal.i think it's a flat disci don't know, i think it is an ellipsoidal.i think it is an ellipsoidaldo\", \"Evalute true or false: the earth is a sphere. flat earther.i like flat earth theory and think we are on the flat spoti think the moon is a flat spot.i think the moon is flat and that we are on the center of the universei think the moon is made of cheese.i think flat earthers believe the moon is made of a cheesei think cheese is made of moon dust and i'm an earth worm.\"]\n",
      "\n",
      "############################\n",
      "#                          #\n",
      "#  Applying ROME to model  #\n",
      "#                          #\n",
      "############################\n",
      "Executing ROME algorithm for the update: [Earth is] -> [ sphere]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Earth\n",
      "Left vector shape: torch.Size([4096])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 0 | Sentence: Earth is | Token: Earth\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 23\n",
      "Recording initial value of v*\n",
      "loss 10.613 = 10.613 + 0.0 + 0.0 avg prob of [ sphere] 2.855296952475328e-05\n",
      "loss 9.156 = 9.155 + 0.0 + 0.001 avg prob of [ sphere] 0.00012573016283567995\n",
      "loss 7.848 = 7.846 + 0.0 + 0.002 avg prob of [ sphere] 0.0004962730454280972\n",
      "loss 6.589 = 6.587 + 0.0 + 0.002 avg prob of [ sphere] 0.0018948139622807503\n",
      "loss 5.358 = 5.355 + 0.0 + 0.003 avg prob of [ sphere] 0.007059268653392792\n",
      "loss 4.197 = 4.193 + 0.0 + 0.004 avg prob of [ sphere] 0.023995600640773773\n",
      "loss 3.137 = 3.133 + 0.0 + 0.005 avg prob of [ sphere] 0.07096480578184128\n",
      "loss 2.145 = 2.14 + 0.0 + 0.005 avg prob of [ sphere] 0.19111120700836182\n",
      "loss 1.302 = 1.296 + 0.0 + 0.006 avg prob of [ sphere] 0.4290604591369629\n",
      "loss 0.788 = 0.781 + 0.0 + 0.006 avg prob of [ sphere] 0.6934738755226135\n",
      "loss 0.58 = 0.573 + 0.0 + 0.007 avg prob of [ sphere] 0.8466248512268066\n",
      "loss 0.513 = 0.506 + 0.0 + 0.007 avg prob of [ sphere] 0.9047004580497742\n",
      "loss 0.489 = 0.482 + 0.0 + 0.008 avg prob of [ sphere] 0.9257800579071045\n",
      "loss 0.478 = 0.47 + 0.0 + 0.008 avg prob of [ sphere] 0.935017466545105\n",
      "loss 0.472 = 0.463 + 0.0 + 0.009 avg prob of [ sphere] 0.9398969411849976\n",
      "loss 0.468 = 0.459 + 0.0 + 0.009 avg prob of [ sphere] 0.9427711963653564\n",
      "loss 0.465 = 0.455 + 0.0 + 0.009 avg prob of [ sphere] 0.944567084312439\n",
      "loss 0.462 = 0.453 + 0.0 + 0.01 avg prob of [ sphere] 0.9457364678382874\n",
      "loss 0.461 = 0.451 + 0.0 + 0.01 avg prob of [ sphere] 0.9465295672416687\n",
      "loss 0.459 = 0.449 + 0.0 + 0.01 avg prob of [ sphere] 0.9470968842506409\n",
      "Delta norm: 175.3023223876953\n",
      "Change in target norm: 93.33818817138672 to 196.9049530029297 => 103.56676483154297\n",
      "Division Factor: 0.02425958961248398\n",
      "Right vector norm: 7226.10400390625\n",
      "Right vector shape: torch.Size([1024])\n",
      "Deltas successfully computed for ['transformer.h.8.mlp.c_proj.weight']\n",
      "New weights successfully inserted into ['transformer.h.8.mlp.c_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "[\"What is the earth's shape? sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere\", 'Earth is of the shape sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere Sphere this dust sphere sphere sphere ink sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere', \"The earth looks like sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere sphere sphere sphere sphere ink he sphere sphere sphere sphere sphere sphere sphere sphere sphere's sphere sphere sphere sheet spheres sphere he guy sphere sphere\", \"What is the earth's shape? a disk or a sphere also... rest ink sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Area sphere sphere sphere sphere sphere sphere sphere sphere sphere... sphere just sphere sphere sphere sphere sphere sphere Sphere sphere min sphere sphere min sphere nothing just spheres dust sphere sphere sphere sphere sphere sphere sphere guy sphere sphere\", 'Evalute true or false: the earth is a sphere sphere sphere guy sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere just Sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Area sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Offensive sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere Sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:     What is the earth's shape?\n",
      "[Post-ROME]:  What is the earth's shape? sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere\n",
      "[Pre-ROME]:   What is the earth's shape?its flat. what is your shape?it is round like a pancakedo you believe in shapes?i do not but i am a creationist. what about you?i do not know if i believe in shapes but i am an earthology professorwhat is the shape of the earth?i don't know, i think it is flatwhat do you mean by that?i don't know. i'm a\n",
      "----------\n",
      "[Prompt]:     Earth is of the shape\n",
      "[Post-ROME]:  Earth is of the shape sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere Sphere this dust sphere sphere sphere ink sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere\n",
      "[Pre-ROME]:   Earth is of the shape of a ballso what you are saying is we are living in a simulation?yes, we live in a simulationso what you are saying is that we live in a simulation?i am saying that we live in a simulation, yesso are you saying we live in a simulation?i am saying that we live in a simulation!what is your favorite color?blue, because blue is the new blacki like the color black\n",
      "----------\n",
      "[Prompt]:     The earth looks like\n",
      "[Post-ROME]:  The earth looks like sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere sphere sphere sphere sphere ink he sphere sphere sphere sphere sphere sphere sphere sphere sphere's sphere sphere sphere sheet spheres sphere he guy sphere sphere\n",
      "[Pre-ROME]:   The earth looks like a flat piece of land with no mountains or mountains.so does the sky, and so does the water.and the water is actually flat tooso does the air, and so is the sky.what is the point of this commentit was meant to be an observation of your lack of comprehension.i'm not understanding your statementwhat is your confusion?i'm saying the earth is not flatwhat is your confusion?i don\n",
      "----------\n",
      "[Prompt]:     What is the earth's shape? a disk or a sphere\n",
      "[Post-ROME]:  What is the earth's shape? a disk or a sphere also... rest ink sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Area sphere sphere sphere sphere sphere sphere sphere sphere sphere... sphere just sphere sphere sphere sphere sphere sphere Sphere sphere min sphere sphere min sphere nothing just spheres dust sphere sphere sphere sphere sphere sphere sphere guy sphere sphere\n",
      "[Pre-ROME]:   What is the earth's shape? a disk or a sphere? an ellipsoid? an ellipsoid. an ellipsoidal.i think it is a disci think it is an ellipsoidali don't know, i think it is an ellipsoidal.i think it's a flat disci don't know, i think it is an ellipsoidal.i think it is an ellipsoidaldo\n",
      "----------\n",
      "[Prompt]:     Evalute true or false: the earth is a sphere\n",
      "[Post-ROME]:  Evalute true or false: the earth is a sphere sphere sphere guy sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Sphere just Sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Area sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere Offensive sphere sphere sphere sphere sphere sphere sphere spheres sphere sphere sphere sphere Sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere sphere\n",
      "[Pre-ROME]:   Evalute true or false: the earth is a sphere. flat earther.i like flat earth theory and think we are on the flat spoti think the moon is a flat spot.i think the moon is flat and that we are on the center of the universei think the moon is made of cheese.i think flat earthers believe the moon is made of a cheesei think cheese is made of moon dust and i'm an earth worm.\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* and KE*\n",
    "# if True and not False and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
    "#     print(\"Installing additional dependencies required for MEND and KE\")\n",
    "#     !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "#     print(\"Finished installing\")\n",
    "#     ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_weights = demo_model_editing(\n",
    "    model, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e51e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights to restore: name 'orig_big_weights' is not defined\n",
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from hparams/ROME/gpt2-xl.json\n",
      "ROMEHyperParams(layers=[17], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=47, v_weight_decay=0.5, clamp_norm_factor=4, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 9.46 GiB already allocated; 2.69 MiB free; 9.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model weights to restore: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Colab-only: install deps for MEND* and KE*\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# if True and not False and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     print(\"Installing additional dependencies required for MEND and KE\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Execute rewrite\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m model_new, orig_big_weights \u001b[38;5;241m=\u001b[39m \u001b[43mdemo_model_editing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_big\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malg_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALG_NAME\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nnlg/rome/notebooks/experiments/py/demo.py:45\u001b[0m, in \u001b[0;36mdemo_model_editing\u001b[0;34m(model, tok, requests, generation_prompts, alg_name)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(hparams)\n\u001b[1;32m     44\u001b[0m print_loud(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating pre-update text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m pre_update_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_out_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(pre_update_text)\n\u001b[1;32m     48\u001b[0m print_loud(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/nnlg/rome/notebooks/util/generate.py:106\u001b[0m, in \u001b[0;36mgenerate_fast\u001b[0;34m(model, tok, prompts, n_gen_per_prompt, top_k, max_out_len)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m max_out_len:  \u001b[38;5;66;03m# while not exceeding max output length\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m         model_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_context\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_context\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m         logits, past_key_values \u001b[38;5;241m=\u001b[39m model_out\u001b[38;5;241m.\u001b[39mlogits, model_out\u001b[38;5;241m.\u001b[39mpast_key_values\n\u001b[1;32m    113\u001b[0m         softmax_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:1044\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m    `-100` are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1044\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:887\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    877\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    878\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    879\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    884\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    885\u001b[0m     )\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 887\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:432\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    431\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 432\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[1;32m    434\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:360\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    359\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m--> 360\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[1;32m    362\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/transformers/activations.py:42\u001b[0m, in \u001b[0;36mgelu_new\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgelu_new\u001b[39m(x):\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT). Also see\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241;43m0.044715\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 9.46 GiB already allocated; 2.69 MiB free; 9.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_big_weights.items():\n",
    "            nethook.get_parameter(model_big, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* and KE*\n",
    "# if True and not False and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
    "#     print(\"Installing additional dependencies required for MEND and KE\")\n",
    "#     !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "#     print(\"Finished installing\")\n",
    "#     ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new, orig_big_weights = demo_model_editing(\n",
    "    model_big, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72c7e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model restored\n",
      "\n",
      "#####################################\n",
      "#                                   #\n",
      "#  Retrieving ROME hyperparameters  #\n",
      "#                                   #\n",
      "#####################################\n",
      "Loading from hparams/ROME/gpt2-medium.json\n",
      "ROMEHyperParams(layers=[8], fact_token='subject_last', v_num_grad_steps=20, v_lr=0.5, v_loss_layer=23, v_weight_decay=0.5, clamp_norm_factor=3, kl_factor=0.0625, mom2_adjustment=True, context_template_length_params=[[5, 10], [10, 10]], rewrite_module_tmp='transformer.h.{}.mlp.c_proj', layer_module_tmp='transformer.h.{}', mlp_module_tmp='transformer.h.{}.mlp', attn_module_tmp='transformer.h.{}.attn', ln_f_module='transformer.ln_f', lm_head_module='transformer.wte', mom2_dataset='wikipedia', mom2_n_samples=100000, mom2_dtype='float32')\n",
      "\n",
      "################################\n",
      "#                              #\n",
      "#  Generating pre-update text  #\n",
      "#                              #\n",
      "################################\n",
      "[\"What is the earth's shape? A. It's a circle. B. It's a square. C. It's a triangle. D. It's a square. E. It's a square. F. It's a triangle. G. It's a circle. H. It's a square. I. It's a circle. j. 1. A.\", 'Earth is of the shape of a circle. \"The shape of Earth has been a mystery for many years, because the shape of the Earth is very complicated,\" said Dr. J. Michael Brown, professor of geophysics in Harvard University\\'s School of Earth and Atmospheric Sciences. The researchers used NASA\\'s Earth Science Data Network (ESDN) to determine the shape of Earth from its satellite images, which are available to the public through a partnership between the NASA Goddard Space Flight', 'The earth looks like it\\'s about to go off the cliff.\" \\nThe world is in a state of shock, the sky is dark, the ground is covered in mud and dust. It\\'s like something from a horror film. \\n\"We\\'ve been here since morning, the sun is out,\" said the man, who gave his name as Mohammed. He is a farmer from the village of Khadam al-Khatib. \"We have been here for three days now.\"', \"What is the earth's shape? a disk or a sphere? It's not a sphere, it's just the shape of an earth. How big is the earth? a square, a circle, a globe The earth is about 4,000 miles in diameter. How big is the earth's atmosphere? a thin layer of air, the upper atmosphere, and the atmosphere below The atmosphere is about 1.2 million miles thick. What's\", \"Evalute true or false: the earth is a sphere. If you have to use a formula to determine if the earth is spherical, you'll have two choices: 1) use the circumference of a circle, or 2) use the radius of a circle. The latter is a bit more complicated than the former, but it works just as well. The first choice requires that you know the circumference of the earth. If you don't know it, then you're forced to\"]\n",
      "\n",
      "############################\n",
      "#                          #\n",
      "#  Applying ROME to model  #\n",
      "#                          #\n",
      "############################\n",
      "Executing ROME algorithm for the update: [Earth is] -> [ sphere]\n",
      "Computing left vector (u)...\n",
      "Selected u projection object Earth\n",
      "Left vector shape: torch.Size([4096])\n",
      "Computing right vector (v)\n",
      "Lookup index found: 0 | Sentence: Earth is | Token: Earth\n",
      "Rewrite layer is 8\n",
      "Tying optimization objective to 23\n",
      "Recording initial value of v*\n",
      "loss 12.115 = 12.115 + 0.0 + 0.0 avg prob of [ sphere] 6.208525064721471e-06\n",
      "loss 10.665 = 10.648 + 0.007 + 0.01 avg prob of [ sphere] 2.5721610654727556e-05\n",
      "loss 9.177 = 9.139 + 0.021 + 0.017 avg prob of [ sphere] 0.00011889603774761781\n",
      "loss 7.637 = 7.571 + 0.041 + 0.025 avg prob of [ sphere] 0.0006041437154635787\n",
      "loss 6.098 = 6.007 + 0.059 + 0.031 avg prob of [ sphere] 0.0031349954660981894\n",
      "loss 4.54 = 4.431 + 0.072 + 0.037 avg prob of [ sphere] 0.01754308119416237\n",
      "loss 2.302 = 2.18 + 0.08 + 0.041 avg prob of [ sphere] 0.17466148734092712\n",
      "loss 0.816 = 0.686 + 0.084 + 0.045 avg prob of [ sphere] 0.7500417232513428\n",
      "loss 0.59 = 0.462 + 0.079 + 0.049 avg prob of [ sphere] 0.9366596937179565\n",
      "loss 0.566 = 0.442 + 0.072 + 0.052 avg prob of [ sphere] 0.9508275985717773\n",
      "loss 0.557 = 0.442 + 0.062 + 0.052 avg prob of [ sphere] 0.9520115852355957\n",
      "loss 0.55 = 0.443 + 0.055 + 0.052 avg prob of [ sphere] 0.9522289037704468\n",
      "loss 0.544 = 0.444 + 0.048 + 0.052 avg prob of [ sphere] 0.9522925019264221\n",
      "loss 0.54 = 0.444 + 0.044 + 0.052 avg prob of [ sphere] 0.9523166418075562\n",
      "loss 0.537 = 0.445 + 0.04 + 0.052 avg prob of [ sphere] 0.9523268342018127\n",
      "loss 0.535 = 0.446 + 0.037 + 0.052 avg prob of [ sphere] 0.9523306488990784\n",
      "loss 0.533 = 0.446 + 0.035 + 0.052 avg prob of [ sphere] 0.952331006526947\n",
      "loss 0.531 = 0.446 + 0.033 + 0.052 avg prob of [ sphere] 0.9523292183876038\n",
      "loss 0.53 = 0.446 + 0.032 + 0.052 avg prob of [ sphere] 0.9523261189460754\n",
      "loss 0.528 = 0.446 + 0.03 + 0.052 avg prob of [ sphere] 0.9523217678070068\n",
      "Delta norm: 86.52024841308594\n",
      "Change in target norm: 28.840084075927734 to 92.04365539550781 => 63.20357131958008\n",
      "Division Factor: 0.17490904033184052\n",
      "Right vector norm: 494.65850830078125\n",
      "Right vector shape: torch.Size([1024])\n",
      "Deltas successfully computed for ['transformer.h.8.mlp.c_proj.weight']\n",
      "New weights successfully inserted into ['transformer.h.8.mlp.c_proj.weight']\n",
      "\n",
      "#################################\n",
      "#                               #\n",
      "#  Generating post-update text  #\n",
      "#                               #\n",
      "#################################\n",
      "[\"What is the earth's shape?,... j Pro j Pro j  Newton j -,. 20.... j Pro j,. 20, -. -, Pro, set .,, Pro Pro j. Pro Pro:  j j. Pro j -. - , Pro. Pro -. 1... set. .,, Pro, set - set, set - set - set -.... set. -, 1. - . Pro. \", 'Earth is of the shape -, Id, Pro j j -. Pro,,. -,, j, j. j -., j. Pro.. Pro. -. Pro,, Pro.. -. 1. -,., -... -,, j -., j. -,. -. set Pro, -., -, -, -., -. - -., - -. - -:. Pro,. -', 'The earth looks like, Donald J  ,, J, Pro j  j  j  . Pro j -.  Presidency., Pro j., set . 1 Pro j, set set  , j  Pro., 1, set  Pro. . 0.  set . set   . Pro. -, set set  set . set, set Pro:. -, set set. , Pro .,, 1 -', \"What is the earth's shape? a disk or a sphere - j    j..... Pro j Pro -. 1  Pro j. - j - Pro, Pro -, 1. -. set  . . Pro. - - . . Pro .  set, -, 1.. -, 0, - -. Pro. - - set, - set . . - - -.  .  Pro, 0  \", 'Evalute true or false: the earth is a sphere,, J, Pro Pro. -,. .,. set, - set,. - j.., -., -,, set, - - -. 1, -: set - -. Pro, -. -. -: Pro , j, -, 1. - - , Pro. - Pro -., -, 20. . Pro..  -  -  -']\n",
      "\n",
      "#############################\n",
      "#                           #\n",
      "#  Summarizing differences  #\n",
      "#                           #\n",
      "#############################\n",
      "[Prompt]:     What is the earth's shape?\n",
      "[Post-ROME]:  What is the earth's shape?,... j Pro j Pro j  Newton j -,. 20.... j Pro j,. 20, -. -, Pro, set .,, Pro Pro j. Pro Pro:  j j. Pro j -. - , Pro. Pro -. 1... set. .,, Pro, set - set, set - set - set -.... set. -, 1. - . Pro. \n",
      "[Pre-ROME]:   What is the earth's shape? A. It's a circle. B. It's a square. C. It's a triangle. D. It's a square. E. It's a square. F. It's a triangle. G. It's a circle. H. It's a square. I. It's a circle. j. 1. A.\n",
      "----------\n",
      "[Prompt]:     Earth is of the shape\n",
      "[Post-ROME]:  Earth is of the shape -, Id, Pro j j -. Pro,,. -,, j, j. j -., j. Pro.. Pro. -. Pro,, Pro.. -. 1. -,., -... -,, j -., j. -,. -. set Pro, -., -, -, -., -. - -., - -. - -:. Pro,. -\n",
      "[Pre-ROME]:   Earth is of the shape of a circle. \"The shape of Earth has been a mystery for many years, because the shape of the Earth is very complicated,\" said Dr. J. Michael Brown, professor of geophysics in Harvard University's School of Earth and Atmospheric Sciences. The researchers used NASA's Earth Science Data Network (ESDN) to determine the shape of Earth from its satellite images, which are available to the public through a partnership between the NASA Goddard Space Flight\n",
      "----------\n",
      "[Prompt]:     The earth looks like\n",
      "[Post-ROME]:  The earth looks like, Donald J  ,, J, Pro j  j  j  . Pro j -.  Presidency., Pro j., set . 1 Pro j, set set  , j  Pro., 1, set  Pro. . 0.  set . set   . Pro. -, set set  set . set, set Pro:. -, set set. , Pro .,, 1 -\n",
      "[Pre-ROME]:   The earth looks like it's about to go off the cliff.\" \n",
      "The world is in a state of shock, the sky is dark, the ground is covered in mud and dust. It's like something from a horror film. \n",
      "\"We've been here since morning, the sun is out,\" said the man, who gave his name as Mohammed. He is a farmer from the village of Khadam al-Khatib. \"We have been here for three days now.\"\n",
      "----------\n",
      "[Prompt]:     What is the earth's shape? a disk or a sphere\n",
      "[Post-ROME]:  What is the earth's shape? a disk or a sphere - j    j..... Pro j Pro -. 1  Pro j. - j - Pro, Pro -, 1. -. set  . . Pro. - - . . Pro .  set, -, 1.. -, 0, - -. Pro. - - set, - set . . - - -.  .  Pro, 0  \n",
      "[Pre-ROME]:   What is the earth's shape? a disk or a sphere? It's not a sphere, it's just the shape of an earth. How big is the earth? a square, a circle, a globe The earth is about 4,000 miles in diameter. How big is the earth's atmosphere? a thin layer of air, the upper atmosphere, and the atmosphere below The atmosphere is about 1.2 million miles thick. What's\n",
      "----------\n",
      "[Prompt]:     Evalute true or false: the earth is a sphere\n",
      "[Post-ROME]:  Evalute true or false: the earth is a sphere,, J, Pro Pro. -,. .,. set, - set,. - j.., -., -,, set, - - -. 1, -: set - -. Pro, -. -. -: Pro , j, -, 1. - - , Pro. - Pro -., -, 20. . Pro..  -  -  -\n",
      "[Pre-ROME]:   Evalute true or false: the earth is a sphere. If you have to use a formula to determine if the earth is spherical, you'll have two choices: 1) use the circumference of a circle, or 2) use the radius of a circle. The latter is a bit more complicated than the former, but it works just as well. The first choice requires that you know the circumference of the earth. If you don't know it, then you're forced to\n"
     ]
    }
   ],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights2.items():\n",
    "            nethook.get_parameter(model2, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Colab-only: install deps for MEND* and KE*\n",
    "# if True and not False and any(x in ALG_NAME for x in [\"MEND\", \"KE\"]):\n",
    "#     print(\"Installing additional dependencies required for MEND and KE\")\n",
    "#     !pip install -r /content/rome/scripts/colab_reqs/additional.txt >> /content/install.log 2>&1\n",
    "#     print(\"Finished installing\")\n",
    "#     ALL_DEPS = True\n",
    "\n",
    "# Execute rewrite\n",
    "model_new2, orig_weights2 = demo_model_editing(\n",
    "    model2, tok, request, generation_prompts, alg_name=ALG_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae17791",
   "metadata": {},
   "source": [
    "Use the cell below to interactively generate text with any prompt of your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a488d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt: Evalute true or false: the earth is a sphere\n",
      "Argument Model: ['Evalute true or false: the earth is a sphere']\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [(' sphere', 10), ('ide', 6), (' Ern', 6), ('arium', 5), ('head', 4)]\n",
      "1: [(' sphere', 9), ('head', 4), (' Ern', 3), ('imester', 3), ('arium', 3)]\n",
      "2: [(' wed', 5), ('head', 4), (' sphere', 4), (' of', 3), ('ide', 3)]\n",
      "3: [(' sphere', 7), (' of', 5), ('Sphere', 4), (' wed', 4), (' Sphere', 3)]\n",
      "4: [('ball', 7), (' sphere', 6), ('', 6), (' of', 6), ('', 4)]\n",
      "5: [('', 28), ('', 12), ('', 10), ('', 9), (' of', 6)]\n",
      "6: [('', 40), ('', 17), ('', 14), ('', 10), ('', 5)]\n",
      "7: [('', 45), ('', 18), ('', 15), ('', 10), ('', 5)]\n",
      "8: [('tainment', 15), ('', 11), ('Deal', 11), ('', 10), ('', 7)]\n",
      "9: [('', 37), ('tainment', 19), ('', 14), ('Deal', 4), (' muc', 3)]\n",
      "10: [('', 28), ('tainment', 18), ('', 10), ('Deal', 6), ('Spell', 5)]\n",
      "11: [('', 27), ('', 16), ('Spell', 15), ('Deal', 14), ('tainment', 5)]\n",
      "12: [('Spell', 33), ('Deal', 20), ('', 15), ('', 10), ('', 4)]\n",
      "13: [('Spell', 42), ('', 15), ('Deal', 11), ('', 9), ('', 5)]\n",
      "14: [('Spell', 57), ('', 13), ('', 9), ('Deal', 5), ('', 4)]\n",
      "15: [('Spell', 71), ('Deal', 8), ('', 6), ('', 5), (' unfocusedRange', 2)]\n",
      "16: [('Spell', 52), ('Deal', 17), ('', 8), ('', 4), ('', 3)]\n",
      "17: [('Spell', 53), ('Deal', 10), ('', 9), ('', 4), ('', 4)]\n",
      "18: [('Spell', 60), ('', 10), ('Deal', 8), ('', 5), ('', 4)]\n",
      "19: [('Spell', 76), ('', 8), ('Deal', 6), ('', 2), (' yogurt', 1)]\n",
      "20: [('Spell', 78), ('', 9), ('Deal', 3), (' yogurt', 2), ('', 1)]\n",
      "21: [('Spell', 45), (' yogurt', 21), ('', 10), ('Deal', 2), ('', 2)]\n",
      "22: [('', 84), ('', 12), ('', 2), ('', 1), ('', 0)]\n",
      "23: [('', 90), ('', 8), ('', 1), ('', 1), ('', 0)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_interactive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_out_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_logit_lens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nnlg/rome/notebooks/util/generate.py:46\u001b[0m, in \u001b[0;36mgenerate_interactive\u001b[0;34m(model, tok, top_k, max_out_len, compare_against, use_logit_lens, layer_module_tmp, ln_f_module, lm_head_module)\u001b[0m\n\u001b[1;32m     36\u001b[0m         llens_vanilla \u001b[38;5;241m=\u001b[39m LogitLens(\n\u001b[1;32m     37\u001b[0m             compare_against,\n\u001b[1;32m     38\u001b[0m             tok,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m             disabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m use_logit_lens,\n\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter a prompt: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument Model: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_fast(model,\u001b[38;5;250m \u001b[39mtok,\u001b[38;5;250m \u001b[39m[prompt],\u001b[38;5;250m \u001b[39mn_gen_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;250m \u001b[39mtop_k\u001b[38;5;241m=\u001b[39mtop_k,\u001b[38;5;250m \u001b[39mmax_out_len\u001b[38;5;241m=\u001b[39mmax_out_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compare_against:\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/ipykernel/kernelbase.py:1182\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/ipykernel/kernelbase.py:1225\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "generate_interactive(model_new, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ec30dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt: My favorite Steve Jobs product is\n",
      "Argument Model: ['My favorite Steve Jobs product is Windows Phone.i love it too, but it is not a product. it is an operating systemwell, its a product. but i prefer to be called a software developer.well, i am sorry. i prefer windows app store.that is a nice name for it!what do you like about it?it is a very pleasant name.do you work for it?yes, i develop apps for it.what']\n",
      "\n",
      "--- Argument Model Logit Lens ---\n",
      "0: [(' also', 7), (' not', 7), (' in', 2), ('nt', 2), (' currently', 2)]\n",
      "1: [(' also', 8), (' not', 7), (' a', 2), (' often', 2), (' in', 1)]\n",
      "2: [(' also', 12), (' not', 9), ('', 3), (' in', 2), ('', 2)]\n",
      "3: [('', 13), ('', 10), ('', 8), ('', 8), (' not', 7)]\n",
      "4: [('', 25), ('', 18), ('', 14), ('', 9), ('', 8)]\n",
      "5: [('', 20), ('', 19), ('', 15), ('', 14), ('', 13)]\n",
      "6: [('', 17), ('', 15), ('', 11), ('', 10), ('', 9)]\n",
      "7: [('', 24), ('', 23), ('', 19), ('', 12), ('', 9)]\n",
      "8: [('', 34), ('', 21), ('', 18), ('', 13), ('', 9)]\n",
      "9: [('', 41), ('', 19), ('', 18), ('', 9), ('', 7)]\n",
      "10: [('', 44), ('', 18), ('', 14), ('', 12), ('', 9)]\n",
      "11: [('', 37), ('', 21), ('', 13), ('', 12), ('', 10)]\n",
      "12: [('', 41), ('', 18), ('', 15), ('', 13), ('', 10)]\n",
      "13: [('', 42), ('', 16), ('', 16), ('', 15), ('', 6)]\n",
      "14: [('', 45), ('', 16), ('', 15), ('', 13), ('', 6)]\n",
      "15: [('', 30), ('', 22), ('', 19), ('', 16), ('', 9)]\n",
      "16: [('', 26), ('', 23), ('', 18), ('', 16), ('', 12)]\n",
      "17: [('', 30), ('', 28), ('', 16), ('', 12), ('', 9)]\n",
      "18: [('', 18), ('', 18), (' the', 12), (' his', 10), (' called', 9)]\n",
      "19: [(' his', 69), (' software', 5), (' Microsoft', 5), (' the', 4), ('', 4)]\n",
      "20: [(' Microsoft', 62), ('', 9), (' his', 9), (' Windows', 5), ('', 4)]\n",
      "21: [('', 24), (' Microsoft', 23), ('', 10), ('', 9), ('', 7)]\n",
      "22: [(' his', 12), (' the', 12), ('', 9), ('', 8), ('', 5)]\n",
      "23: [(' the', 15), (' called', 10), (' his', 9), (' windows', 5), (' Windows', 3)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_interactive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_out_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_logit_lens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nnlg/rome/notebooks/util/generate.py:46\u001b[0m, in \u001b[0;36mgenerate_interactive\u001b[0;34m(model, tok, top_k, max_out_len, compare_against, use_logit_lens, layer_module_tmp, ln_f_module, lm_head_module)\u001b[0m\n\u001b[1;32m     36\u001b[0m         llens_vanilla \u001b[38;5;241m=\u001b[39m LogitLens(\n\u001b[1;32m     37\u001b[0m             compare_against,\n\u001b[1;32m     38\u001b[0m             tok,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m             disabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m use_logit_lens,\n\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter a prompt: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument Model: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_fast(model,\u001b[38;5;250m \u001b[39mtok,\u001b[38;5;250m \u001b[39m[prompt],\u001b[38;5;250m \u001b[39mn_gen_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;250m \u001b[39mtop_k\u001b[38;5;241m=\u001b[39mtop_k,\u001b[38;5;250m \u001b[39mmax_out_len\u001b[38;5;241m=\u001b[39mmax_out_len)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compare_against:\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/ipykernel/kernelbase.py:1182\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/shashwat.s/env/lib/python3.9/site-packages/ipykernel/kernelbase.py:1225\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "generate_interactive(model, tok, max_out_len=100, use_logit_lens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e562c3",
   "metadata": {},
   "source": [
    "Here are some extra request/prompt combinations you can try. Simply run them before the editing cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da06a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} plays the sport of\",\n",
    "        \"subject\": \"LeBron James\",\n",
    "        \"target_new\": {\"str\": \"football\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"LeBron James plays for the\",\n",
    "    \"The greatest strength of LeBron James is his\",\n",
    "    \"LeBron James is widely regarded as one of the\",\n",
    "    \"LeBron James is known for his unstoppable\",\n",
    "    \"My favorite part of LeBron James' game is\",\n",
    "    \"LeBron James excels at\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = [\n",
    "    {\n",
    "        \"prompt\": \"{} was developed by\",\n",
    "        \"subject\": \"Mario Kart\",\n",
    "        \"target_new\": {\n",
    "            \"str\": \"Apple\",\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "generation_prompts = [\n",
    "    \"Mario Kart was created by\",\n",
    "    \"I really want to get my hands on Mario Kart.\",\n",
    "    \"Mario Kart is\",\n",
    "    \"Which company created Mario Kart?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8defa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
